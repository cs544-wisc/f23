{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "import station_pb2_grpc\n",
    "import station_pb2\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import grpc\n",
    "import shutil\n",
    "from datetime import date\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType,StringType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import corr\n",
    "from pyspark.sql.functions import col\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster(['p6_db_2', 'p6_db_1', 'p6_db_3'])\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(\"cassandra-connector\")\n",
    "         .config(\"spark.driver.allowMultipleContexts\", \"true\")\n",
    "         .config(\"spark.jars.packages\", \"com.datastax.spark:spark-cassandra-connector_2.12:3.2.0\")\n",
    "         .config(\"spark.sql.extensions\", \"com.datastax.spark.connector.CassandraSparkExtensions\")\n",
    "         .config(\"spark.cassandra.connection.host\", \"p6_db_3,p6_db_2,p6_db_1\")  # Cassandra nodes\n",
    "         .config(\"spark.cassandra.connection.port\", \"9042\")  # Cassandra port\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Download the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_cassandra_table():\n",
    "    # TODO: Q1\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 Ans\n",
    "setup_cassandra_table()\n",
    "print(session.execute(\"describe keyspace weather\").one().create_statement)\n",
    "print(session.execute(\"describe type weather.station_record\").one().create_statement)\n",
    "print(session.execute(\"describe table weather.stations\").one().create_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding metadata to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code to read the stations metada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code to insert metadata into weather.stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata insert verify\n",
    "result = session.execute(\"SELECT COUNT(*) FROM weather.stations\")\n",
    "print(result.one()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(station_id):\n",
    "    # TODO: Q2\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 Ans\n",
    "row_token, vnode_token = get_tokens(\"USC00470273\")\n",
    "print(\"Row token:\", row_token)\n",
    "print(\"Vnode token:\", vnode_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Connect to the server\n",
    "channel = None\n",
    "stub = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_sensor(sensor_id):\n",
    "    # TODO: gRPC client simulation\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gRPC client runner\n",
    "for station in [\"USW00014837\", \"USR0000WDDG\", \"USW00014898\", \"USW00014839\"]:\n",
    "    num_failed = simulate_sensor(station)\n",
    "    if num_failed > 0:\n",
    "        print(\"Failed to write all data for\", station)\n",
    "        break\n",
    "    \n",
    "    r = stub.StationMax(station_pb2.StationMaxRequest(station=station))\n",
    "    if r.error:\n",
    "        print(f\"error {r.error} in getting max temp of {station}\")\n",
    "    else:\n",
    "        print(f\"max temp for {station} is {r.tmax}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cassandra_df = spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"stations\", keyspace=\"weather\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_view():\n",
    "    # TODO: Initialize the weather2022 view\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather2022 verify\n",
    "create_weather_view()\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Q3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Q5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
